{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdullahHassan176/FinGanFlow/blob/main/Implementation_of_GAN_for_beginners.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Ol-kCTdZ-rpS"
      },
      "cell_type": "markdown",
      "source": [
        "# Implementation of GAN for beginners.\n",
        "\n",
        "**generative adversarial networks (GANs)** are able to learn how to reproduce synthetic data that looks real. GANs is ***the most interesting idea in the last 10 years in ML,*** by Yann LeCun, one of the fathers of deep learning.\n",
        "In this notebook, we will going to train a GAN to reproduce our dataset.\n",
        "To facilitate understanding, i chose to do simple with the dataset. So i choose to create a dataset by generating random numbers following normal law. Thus, we can change the parameter(`maen` and `stddev`) of this low to observe the impact on the GAN learning and for more fun.\n",
        "GAN is not only for image data. We will going to train GAN on simple numerical one dimension data.\n",
        "\n",
        "For more understanding of GAN concept, please visit this notebook https://www.kaggle.com/roblexnana/understanding-generative-models-gan\n",
        "\n",
        "### Table of interest:\n",
        "1. Create our dataset.\n",
        "2. Define our generator and our disciminator.\n",
        "3. Define our losses functions.\n",
        "4. Define the optimizers and the train operations.\n",
        "5. Training and visualization of results.\n",
        "\n",
        "Let's get started."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "sRKYueUX-rpU"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "id": "29dCxYcB-rpW"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Create our dataset."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "hLMVAivd-rpW",
        "outputId": "be1d2e9e-a336-4355-faf4-f8f7989a006d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "cell_type": "code",
      "source": [
        "# fonction to generate our dataset\n",
        "def sample_dataset():\n",
        "    dataset_shape = (2000, 1)\n",
        "    return tf.random.normal(mean=8., shape=dataset_shape, stddev=0.5, dtype=tf.float32)\n",
        "\n",
        "# visualize our data with histogram\n",
        "plt.hist(sample_dataset().numpy(), 100)\n",
        "axes = plt.gca()\n",
        "axes.set_xlim([-1,11])\n",
        "axes.set_ylim([0, 70])\n",
        "plt.show()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "kHG0w1t9-rpW"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Define our generator and our disciminator."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "LP6uNEg5-rpW"
      },
      "cell_type": "code",
      "source": [
        "def generator(input_shape):\n",
        "    \"\"\"Defines the generator keras.Model.\n",
        "    Args:\n",
        "        input_shape: the desired input shape (e.g.: (latent_space_size))\n",
        "    Returns:\n",
        "        G: The generator model\n",
        "    \"\"\"\n",
        "    inputs = Input(input_shape)\n",
        "    net = Dense(units=64, activation=tf.nn.elu, name=\"fc1\")(inputs)\n",
        "    net = Dense(units=64, activation=tf.nn.elu, name=\"fc2\")(net)\n",
        "    net = Dense(units=1, name=\"G\")(net)\n",
        "    G = Model(inputs=inputs, outputs=net)\n",
        "    return G\n",
        "\n",
        "def disciminator(input_shape):\n",
        "    \"\"\"Defines the Discriminator keras.Model.\n",
        "    Args:\n",
        "        input_shape: the desired input shape (e.g.: (the generator output shape))\n",
        "    Returns:\n",
        "        D: the Discriminator model\n",
        "    \"\"\"\n",
        "    inputs = Input(input_shape)\n",
        "    net = Dense(units=32, activation=tf.nn.elu, name=\"fc1\")(inputs)\n",
        "    net = Dense(units=1, name=\"D\")(net)\n",
        "    D = Model(inputs=inputs, outputs=net)\n",
        "    return D\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "3ZtrHatM-rpX"
      },
      "cell_type": "code",
      "source": [
        "# Define the real input shape\n",
        "input_shape = (1,)\n",
        "\n",
        "# Define the Discriminator model\n",
        "D = disciminator(input_shape)\n",
        "\n",
        "# Arbitrary set the shape of the noise prior\n",
        "latent_space_shape = (100,)\n",
        "# Define the input noise shape and define the generator\n",
        "G = generator(latent_space_shape)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HBM6rxFP-rpX"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Define our losses functions"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "gGxZt36O-rpX"
      },
      "cell_type": "code",
      "source": [
        "# Define the losses fonctions to optimize\n",
        "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "# Distriminator loss foction\n",
        "def d_loss(d_real, d_fake):\n",
        "    \"\"\"The disciminator loss function.\"\"\"\n",
        "    return bce(tf.ones_like(d_real), d_real) + bce(tf.zeros_like(d_fake), d_fake)\n",
        "# Generator loss fonction\n",
        "def g_loss(generated_output):\n",
        "    \"\"\"The Generator loss function.\"\"\"\n",
        "    return bce(tf.ones_like(generated_output), generated_output)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-rjcFuqn-rpY"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Define the optimizers and the train operations."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "uLIZyRx5-rpY"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the optimizers and the train operations\n",
        "optimizer = tf.keras.optimizers.Adam(1e-5)\n",
        "\n",
        "@tf.function\n",
        "def train_step():\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        real_data = sample_dataset()\n",
        "        noise_vector = tf.random.normal(\n",
        "            mean=0, stddev=1,\n",
        "            shape=(real_data.shape[0], latent_space_shape[0]))\n",
        "        # Sample from the Generator\n",
        "        fake_data = G(noise_vector)\n",
        "        # Compute the D loss\n",
        "        d_fake_data = D(fake_data)\n",
        "        d_real_data = D(real_data)\n",
        "        d_loss_value = d_loss(d_real_data, d_fake_data)\n",
        "        # Compute the G loss\n",
        "        g_loss_value = g_loss(d_fake_data)\n",
        "    # Now that we comptuted the losses we can compute the gradient\n",
        "    # and optimize the networks\n",
        "    d_gradients = tape.gradient(d_loss_value, D.trainable_variables)\n",
        "    g_gradients = tape.gradient(g_loss_value, G.trainable_variables)\n",
        "    # Deletng the tape, since we defined it as persistent\n",
        "    # (because we used it twice)\n",
        "    del tape\n",
        "    optimizer.apply_gradients(zip(d_gradients, D.trainable_variables))\n",
        "    optimizer.apply_gradients(zip(g_gradients, G.trainable_variables))\n",
        "    return real_data, fake_data, g_loss_value, d_loss_value\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y-u8TeOL-rpY"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. Training and visualization of results."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "PhnRmiMz-rpY",
        "outputId": "feaf34d1-8a87-42ca-f434-8a76e4e663e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 982
        }
      },
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "for step in range(30000):\n",
        "    real_data, fake_data, g_loss_value, d_loss_value = train_step()\n",
        "    if step % 2000 == 0:\n",
        "        print(\"G loss: \", g_loss_value.numpy(), \" D loss: \", d_loss_value.numpy(), \" step: \", step)\n",
        "\n",
        "        # Sample 5000 values from the Generator and draw the histogram\n",
        "        ax.hist(fake_data.numpy(), 100)\n",
        "        ax.hist(real_data.numpy(), 100)\n",
        "        # these are matplotlib.patch.Patch properties\n",
        "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
        "\n",
        "        # place a text box in upper left in axes coords\n",
        "        textstr = f\"step={step}\"\n",
        "        ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=14,\n",
        "                verticalalignment='top', bbox=props)\n",
        "\n",
        "        axes = plt.gca()\n",
        "        axes.set_xlim([-1,11])\n",
        "        axes.set_ylim([0, 60])\n",
        "        display(plt.gcf())\n",
        "        plt.gca().clear()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"<ipython-input-6-43c8ca57cd37>\", line 27, in train_step  *\n        optimizer.apply_gradients(zip(g_gradients, G.trainable_variables))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\", line 282, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\", line 323, in apply\n        self._check_variables_are_known(trainable_variables)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\", line 228, in _check_variables_are_known\n        raise ValueError(\n\n    ValueError: Unknown variable: <KerasVariable shape=(100, 64), dtype=float32, path=fc1/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-2540d95989a7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mreal_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"G loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" D loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" step: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_fileij6kzzwv.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mtape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_gradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_gradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0;31m# Return iterations for compat with tf.keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    321\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables_are_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36m_check_variables_are_known\u001b[0;34m(self, variables)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable_variables_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    229\u001b[0m                     \u001b[0;34mf\"Unknown variable: {v}. This optimizer can only \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                     \u001b[0;34m\"be called for the variables it was originally built with. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"<ipython-input-6-43c8ca57cd37>\", line 27, in train_step  *\n        optimizer.apply_gradients(zip(g_gradients, G.trainable_variables))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\", line 282, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\", line 323, in apply\n        self._check_variables_are_known(trainable_variables)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\", line 228, in _check_variables_are_known\n        raise ValueError(\n\n    ValueError: Unknown variable: <KerasVariable shape=(100, 64), dtype=float32, path=fc1/kernel>. This optimizer can only be called for the variables it was originally built with. When working with a new set of variables, you should recreate a new optimizer instance.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "y_s8BO2U-rpY"
      },
      "cell_type": "markdown",
      "source": [
        "**Hope that you find this notebook helpful. More to come.**\n",
        "\n",
        "**Please upvote this, to keep me motivate for doing better.**\n",
        "\n",
        "**Thanks.**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Implementation of GAN for beginners",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}